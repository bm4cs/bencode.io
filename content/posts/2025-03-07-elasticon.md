---
layout: post
draft: false
title: "ElasticON 2025 Takeaways"
slug: "elasticon"
date: "2025-03-07 7:16:56+1100"
lastmod: "2025-03-06 7:16:56+1100"
comments: false
categories:
  - elasticsearch
---

ElasticON in Sydney March 2025 was a great day, its was mix of technical and business executive content, with interviews from several partners such as Spark NZ and AWS The keynote from Ken Exner and Baha Azarmi was slick, showing hot off the press GenAI features throughout the stack include the new `semantic_text` field type, RRF, BBQ, LogsDB mode and the ability to ETL unstructured data onto ECS using an LLM and ability to join data with the new ESQL query engine. The conference highlighted just how firmly Elastic has its targets set on GenAI and its bold plans for future. No longer just a platform dumping a copy of your data or logs for lexical search (BM25) and observabilty, but now also a platform for making and storing semantic embeddings, orchestrating RAG activity such as chunking, taking on ETL concerns and doing LLM integration for supported "foundational models".

- [BBQ - Better Binary Quantization](#bbq---better-binary-quantization)
- [Sparse vectors and semantic search](#sparse-vectors-and-semantic-search)
- [Semantic Text Field Type and Semantic Query](#semantic-text-field-type-and-semantic-query)
- [Hybrid with Reciprocal Rank Fusion (RRF)](#hybrid-with-reciprocal-rank-fusion-rrf)
- [GenAI and free tier](#genai-and-free-tier)
- [Developer quality of life improvements](#developer-quality-of-life-improvements)
  - [ES|QL and joins](#esql-and-joins)
  - [start-local](#start-local)
  - [OTel all the things](#otel-all-the-things)
  - [Platform consolidation](#platform-consolidation)
  - [JVM and native code improvements](#jvm-and-native-code-improvements)
- [SaaS](#saas)

## BBQ - Better Binary Quantization

An efficency overlay that pushes quantization to its limits. The ability to accelerate vector quantization times by 20-30x and reducing vector memory by upto 95x, while accelerating search performance and maintaining retrieval accuracy.

_Dense vectors_ are multidimensional vectors usually of float type that stores the embeddings generated by ML model for given input such as text or image bytes. The higher the dimensionality the more expensive it is to compute the similarity of vectors.

_Quantization_ improves similarity calculation performance at query time by compressing dense vector dimensions into more simple data structures, enabling faster similarity calculations at the cost or lower accuracy. The quantized information is stored to the disk together with the raw data and same quantization is then applied to search request vector to calculate similarities with quantized values instead of raw vectors.

Simple quantization squashes 32-bit float into an 8-bit integer, similarly with a 4-bit integer and so on. Leaner data representation however comes at the expense of accuracy. BBQ leverages [Optimized Scalar Quantization](https://www.elastic.co/search-labs/blog/optimized-scalar-quantization-elasticsearch) (OSQ), which increases recall quality and can produce binary quantization to any number of bits to control ratio between speed and recall quality.

Searching for approximate nearest neighbors (ANN) in the high-dimensional Euclidean space is a pivotal problem, read white paper [RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2405.12497).

## Sparse vectors and semantic search

Sparse vectors are usually embeddings of text in form of a set of key-value pairs, where key is called "feature" and the value "weight" . For example, text Pablo Picasso can be embedded into sparse vector:

```json
{
  "picasso": 2.6674592,
  "pablo": 2.1023502,
  "artist": 1.0236684,
  "art": 0.93684757,
  "painting": 0.92193965
}
```

At query time a cross product of features is evaluated. For example a search for "painting" will result in a hit on document with field value "Pablo Picasso".

## Semantic Text Field Type and Semantic Query

With the new `semantic_text` field type, sparse vectors are used automatically in the background, given you a basic out of the box semantic search.

To generate the sparse vector embeddings easily, you can use Elastic built-in ML models, for example `ELSER` for English. Combining these together is the simplest and fastest way to get you started with semantic and hybrid search using Elasticsearch.

## Hybrid with Reciprocal Rank Fusion (RRF)

Linear combination is execution of hybrid search (full-text and semantic) as boolean query where full-text and hybrid queries are AND-ed or OR-red together. This technique is still relevant and usually requires careful boost tuning, as full-text queries usually scores very differently from semantic ones, and combining scores without normalization can cause ranking issues.

[RRF](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html), on another hand, requires no normalization. It works with the relative position of given result item across different full-text and semantic queries, and averages the rank based on that. Conceptually, a document with ID 1 is returned as a 1st document in your full-text query, and as a last document in your semantic query, RRF put’s the document somewhere in the middle of result set.

## GenAI and free tier

Amoung the cool demos, it felt murky what was possible in free tier. If a solution couples GenAI to this platform, what does that translate to in terms of licencing obligations. Yes there is a feature matrix and vectors are included. I need to pick and choose the trade-offs between the 3 licence tiers of free, platnium and enterprise in the context of designing and building complex RAG architectures for my customers. I suspect the field of GenAI is moving too fast and fluid right now for Elastic (or anyone) to dial into what customers problems and needs are in this space. To further complicate matters there is allot of competition such as [OpenSearch AI search](https://opensearch.org/docs/latest/vector-search/ai-search/index/) which is evolving rapidly.

Elastic historically was always liberal with its open source base Lucene platform, which gave rise to its dominance, you could buy the XPack for nice-to-have features, but it doesn't feel like the same anymore in this new GenAI world. Elastic is also a gigantic publically listed corporation now too, maybe its all related IDK.

## Developer quality of life improvements

Amoung the AI hype, I was interested in technical investments being made in legacy BM25, Kibana and general platform consolidation.

### ES|QL and joins

The new query engine and language. The "killer demo" was how its now possible for ES to scalably deal with joins. This is massive and has been one of Elasticsearch most renknown and hardcore opinions. You don't join data, ever. Yes its efficient and just works. There are plans to migrate existing query API over ESQL.

### start-local

Some developer quality of life improvements like [start-local](https://www.elastic.co/guide/en/elasticsearch/reference/current/run-elasticsearch-locally.html)

### OTel all the things

Elastic is ditching proprietry instrumentation throughout the eco-system. In 9.x Elasticsearch will be able to absorb otel signals directly, without the need for APM and translation layers. Many of the announcments highlighted how the company is making open source contributing in particular to OpenTelemetry.

### Platform consolidation

It's clear the platform is taking a different direction strategically than it has over the last several years. I suspect there will be sunsetting dates coming for products like enterprise search, APM, beats, logstash, etc coming soon.

### JVM and native code improvements

JDK 20 introduced project Panama.

> We are improving and enriching the connections between the Java virtual machine and well-defined but “foreign” (non-Java) APIs, including many interfaces commonly used by C programmers.

Elastic are refactoring intensive compute workloads to leverage instruction level optimisations such as SIMD and fused multiply-add.

## SaaS

There is now a completely managed SaaS offering. Elastic has always edge away from managing live deployments, taking a more "its up to you" approach, managing and being accountable for customers production data platforms is a scary thought to be honest. Well they've taken that leap.
